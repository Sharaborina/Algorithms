{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main ChatBot project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOktsKqjkBzUMaCDw+gu+uf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sharaborina/algorithms/blob/master/Main_ChatBot_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzIoNY81JHZl",
        "outputId": "75c23eb7-022c-4661-ae2a-d5f63873c9c9"
      },
      "source": [
        "!pip uninstall -y spacy --quiet\n",
        "!pip install python-telegram-bot nltk geopy dateparser datefinder spacy deep_translator detectlanguage geotext \n",
        "!python -m spacy download en_core_web_lg >out 2>log\n",
        "!python -m spacy download da_core_news_lg >out 2>log\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-telegram-bot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/44/1726f407387a7332a08b4e95211380b3bda185cedbe73d1058010136e695/python_telegram_bot-13.5-py3-none-any.whl (455kB)\n",
            "\r\u001b[K     |▊                               | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 20.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 16.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40kB 15.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 61kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 81kB 10.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 92kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 102kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 122kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 133kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 143kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 153kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 163kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 174kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 184kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 194kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 204kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 215kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 225kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 235kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 245kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 256kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 266kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 276kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 286kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 296kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 307kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 317kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 327kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 337kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 348kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 358kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 368kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 378kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 389kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 399kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 409kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 419kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 430kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 440kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 450kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 460kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (1.17.0)\n",
            "Collecting dateparser\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/c4/b5ddc3eeac974d85055d88c1e6b62cc492fc1a93dbe3b66a45a756a7b807/dateparser-1.0.0-py2.py3-none-any.whl (279kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 47.3MB/s \n",
            "\u001b[?25hCollecting datefinder\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/4f/29524c9ca35d2ba1a8a3c6c895b90fc92525cf0fe357f747133890953ebe/datefinder-0.7.1-py2.py3-none-any.whl\n",
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 54.2MB/s \n",
            "\u001b[?25hCollecting deep_translator\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/71/b2939e3d1ccd91c5eba61718d183c607486089d509141e9cbe594cca873b/deep_translator-1.4.4-py2.py3-none-any.whl\n",
            "Collecting detectlanguage\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/26/bec6bce0f6a58ba99efe03ef37ef39ae98eb3331738195fecdec1eae0218/detectlanguage-1.5.0.tar.gz\n",
            "Collecting geotext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/c5/36351193092cb4c1d7002d2a3babe5e72ae377868473933d6f63b41e5454/geotext-0.4.0-py2.py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (5.1.1)\n",
            "Requirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2018.9)\n",
            "Collecting APScheduler==3.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/34/9ef20ed473c4fd2c3df54ef77a27ae3fc7500b16b192add4720cab8b2c09/APScheduler-3.6.3-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy) (1.50)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser) (2019.12.20)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser) (2.8.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Collecting thinc<8.1.0,>=8.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/87/decceba68a0c6ca356ddcb6aea8b2500e71d9bc187f148aae19b747b7d3c/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.1.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Collecting catalogue<2.1.0,>=2.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/fa/d43f31874e1f2a9633e4c025be310f2ce7a8350017579e9e837a62630a7e/pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 40.2MB/s \n",
            "\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 46.8MB/s \n",
            "\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Collecting pathy>=0.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from deep_translator) (4.6.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Collecting smart-open<4.0.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 54.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: detectlanguage, smart-open\n",
            "  Building wheel for detectlanguage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectlanguage: filename=detectlanguage-1.5.0-cp37-none-any.whl size=3173 sha256=2cf61d7e94a242806261e22fd102e7d56da17f817a0b6ad73dd551d28cdf65a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/30/66/53f3628609941078e5a3fb763a78010dbd64b996cac518b15b\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=b58bf7e5cffd8b6b555366ed35c12f9b9484da29287a53e882cd66a943460024\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
            "Successfully built detectlanguage smart-open\n",
            "Installing collected packages: APScheduler, python-telegram-bot, dateparser, datefinder, pydantic, catalogue, srsly, thinc, spacy-legacy, typer, smart-open, pathy, spacy, deep-translator, detectlanguage, geotext\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: smart-open 5.0.0\n",
            "    Uninstalling smart-open-5.0.0:\n",
            "      Successfully uninstalled smart-open-5.0.0\n",
            "Successfully installed APScheduler-3.6.3 catalogue-2.0.4 datefinder-0.7.1 dateparser-1.0.0 deep-translator-1.4.4 detectlanguage-1.5.0 geotext-0.4.0 pathy-0.5.2 pydantic-1.7.4 python-telegram-bot-13.5 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccfHsxynJJb9"
      },
      "source": [
        "from telegram.ext import *\n",
        "import telegram\n",
        "import random\n",
        "import pandas as pd\n",
        "import requests\n",
        "import geopy\n",
        "import torch\n",
        "import re\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from geopy.geocoders import Nominatim\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "#for intention classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "#telegram bot logging/debugging\n",
        "import logging\n",
        "logging.basicConfig(level=logging.DEBUG,\n",
        "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "#for date analyser\n",
        "# from date_extractor import extract_dates\n",
        "import dateparser #text to date\n",
        "from datetime import timedelta\n",
        "from datetime import datetime\n",
        "import datefinder\n",
        "\n",
        "#for geo extraction\n",
        "from geotext import GeoText #only in English\n",
        "\n",
        "# NLU\n",
        "import nltk\n",
        "import spacy\n",
        "# translate replicas\n",
        "from deep_translator import GoogleTranslator, single_detection\n",
        "# detect language\n",
        "# import detectlanguage\n",
        "import itertools\n",
        "\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV-b_vY8KPNA"
      },
      "source": [
        "#bot token\n",
        "BOT_KEY = '1880919831:AAEJFa4yGm57IKr68qXEHYS7t1nS_LnX8iw'\n",
        "\n",
        "NER_MODEL_DIR='/content/drive/MyDrive/ColabNotebooks/Spacy_NER_Model'\n",
        "\n",
        "GENERATIVE_MODEL_DIR='/content/drive/MyDrive/ColabNotebooks/Generative_model'\n",
        "# data directory\n",
        "DATA_DIR = '/content/drive/MyDrive/ColabNotebooks/MultiWoz/'\n",
        "# vocabulary filename\n",
        "VOCAB_FILE = 'en_50k_pruned.subword'\n",
        "# vocabulary file directory\n",
        "VOCAB_DIR = '/content/drive/MyDrive/ColabNotebooks/MultiWoz/'\n",
        "VOCAB_SIZE = 50000\n",
        "\n",
        "# load a cleaned translated train data from file DATA_DIR/TRAIN_FILENAME, \n",
        "# otherwise  generate a train data from DIALOGUE_ENG_DB\n",
        "LOAD_TRAIN_DATA = False\n",
        "# train filename\n",
        "TRAIN_FILENAME = 'label_and_train_data.json'\n",
        "# path to pretrained NER_model\n",
        "NER_MODEL_DIR = '/content/drive/MyDrive/ColabNotebooks/Spacy_NER_Model'\n",
        "\n",
        "GENERATIVE_MODEL_SH = '/content/drive/MyDrive/ColabNotebooks/Generative_model_Sharaborina_state_dict.pt'\n",
        "\n",
        "\n",
        "USE_PRETRAINED_MODEL = True #use pretrained model, otherwise start from a blank model\n",
        "LOAD_MODEL = True #load pretrained model\n",
        "TRAIN = True\n",
        "N_LAYERS = 6\n",
        "TRAIN_STEPS = 100\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A86DH3Z3KahH"
      },
      "source": [
        "# Booking API\n",
        "First let's create a `geoloc` function to find out latitude and longitude of a city/town/village, etc. Because Booking API works only with such coordinates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGkDbbqjLxIV"
      },
      "source": [
        "def geoloc(city):\n",
        "    geolocator = Nominatim(user_agent= 'sharaborinaly')\n",
        "    location = geolocator.geocode(city)\n",
        "    result = str(location.latitude-0.3)+'%2C'+str(location.latitude+0.3)+'%2C'+str(location.longitude-0.3)+'%2C'+str(location.longitude+0.3)\n",
        "    return result"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymEm8yhqMi8P"
      },
      "source": [
        "`booking_request` function gives us scraped data from the booking site. It takes required fileds: the name of city, arrival and departure dates, the number of guests.\n",
        "Also there is not mandatory fields: the number of children, number of rooms, number of guests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2b5U_KjKZ8b"
      },
      "source": [
        "def booking_request(city, dates = None, rooms = 1, guest = 1, children = 0):\n",
        "\n",
        "    dates = sorted(dates)\n",
        "    arrival_date = str(dates[0].date())\n",
        "    departure_date = str(dates[1].date())\n",
        "\n",
        "    if arrival_date == None or departure_date == None:\n",
        "      arrival_date = datetime.today()\n",
        "      departure_date = arrival_date + 1\n",
        "\n",
        "    list_by_map_url = \"https://apidojo-booking-v1.p.rapidapi.com/properties/list-by-map\"\n",
        "\n",
        "    list_by_map_querystring = {\n",
        "        \"search_id\":\"none\",\n",
        "        \"children_age\":\"\",\n",
        "        \"price_filter_currencycode\":\"EUR\",\n",
        "        \"languagecode\":\"da\",\n",
        "        \"travel_purpose\":\"leisure\",\n",
        "        \"categories_filter\":\"class%3A%3A1%2Cclass%3A%3A2%2Cclass%3A%3A3\",\n",
        "        \"children_qty\":children,\n",
        "        \"order_by\":\"popularity\",\n",
        "        \"guest_qty\": guest,\n",
        "        \"room_qty\": rooms,\n",
        "        \"departure_date\": departure_date,\n",
        "        \"bbox\":\"\",\n",
        "        \"arrival_date\": arrival_date\n",
        "    }\n",
        "    \n",
        "    list_by_map_querystring['bbox'] = geoloc(city) \n",
        "    list_by_map_headers = {\n",
        "        'x-rapidapi-host': \"apidojo-booking-v1.p.rapidapi.com\",\n",
        "        'x-rapidapi-key': \"54d78e5c98mshd2b3a25b4adf763p1674f2jsnb7535d954daf\"\n",
        "    }\n",
        "\n",
        "    list_by_map_response = requests.request(\"GET\", list_by_map_url, headers=list_by_map_headers, params=list_by_map_querystring).json()\n",
        "    result = []\n",
        "    # prdic(list_by_map_response['result'])\n",
        "    try:\n",
        "      for list_result in list_by_map_response['result']:\n",
        "          result.append({'hotel_id': list_result['hotel_id'],\n",
        "                        'hotel_name': list_result['hotel_name'],\n",
        "                        'url':list_result['url'],\n",
        "                        'main_photo_url' : list_result['main_photo_url'],\n",
        "                        'min_total_price': list_result['min_total_price'],\n",
        "                        'address': list_result['address'],\n",
        "                        'review_score': list_result['review_score'],\n",
        "                        'currencycode' : list_result['currencycode']\n",
        "                        })\n",
        "    except:\n",
        "      pass    \n",
        "   \n",
        "    if len(result) == 0:\n",
        "      return 'Undskyld! Jeg kan ikke finde hoteller til de givne datoer. Prøv venligst andre datoer.' \n",
        "    elif len(result) <= 5:\n",
        "      return result\n",
        "    else:\n",
        "      return result[:5]\n",
        "        "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIrtmnytwEYD",
        "outputId": "f4145c0e-1a3f-4cd3-f1a1-8d5f03e35021"
      },
      "source": [
        "# !pip install print_dict\n",
        "# from print_dict import pd as prdic\n",
        "# # Let's check the output\n",
        "booking_request('Moskva', [datetime.today(), datetime.today() + timedelta(days=3)])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-30 18:05:00,374 - geopy - DEBUG - Nominatim.geocode: https://nominatim.openstreetmap.org/search?q=Moskva&format=json&limit=1\n",
            "2021-05-30 18:05:00,478 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): apidojo-booking-v1.p.rapidapi.com:443\n",
            "2021-05-30 18:05:01,937 - urllib3.connectionpool - DEBUG - https://apidojo-booking-v1.p.rapidapi.com:443 \"GET /properties/list-by-map?search_id=none&children_age=&price_filter_currencycode=EUR&languagecode=da&travel_purpose=leisure&categories_filter=class%253A%253A1%252Cclass%253A%253A2%252Cclass%253A%253A3&children_qty=0&order_by=popularity&guest_qty=1&room_qty=1&departure_date=2021-06-02&bbox=55.4504461%252C56.050446099999995%252C37.3174943%252C37.917494299999994&arrival_date=2021-05-30 HTTP/1.1\" 200 52504\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'address': 'Izmailovskoe Shosse 71, 4 G - D',\n",
              "  'currencycode': 'RUB',\n",
              "  'hotel_id': 245721,\n",
              "  'hotel_name': 'Izmailovo Gamma Hotel',\n",
              "  'main_photo_url': 'https://cf.bstatic.com/xdata/images/hotel/square60/287211548.jpg?k=8d1614b23879d4250db3c1a4e5b86d5d888888c89449ac311f700b203bdc2bc1&o=',\n",
              "  'min_total_price': 6600,\n",
              "  'review_score': 8.7,\n",
              "  'url': 'https://www.booking.com/hotel/ru/izmailovo-gamma.html'},\n",
              " {'address': 'Izmailovskoye Shosse 71 Bld.2B',\n",
              "  'currencycode': 'RUB',\n",
              "  'hotel_id': 269458,\n",
              "  'hotel_name': 'Izmailovo Beta Hotel',\n",
              "  'main_photo_url': 'https://cf.bstatic.com/xdata/images/hotel/square60/90460449.jpg?k=d523769f5f5e3a11321fb347eec460eafedbd875c098297fd4f4477e8b1deafd&o=',\n",
              "  'min_total_price': 10483,\n",
              "  'review_score': 8.1,\n",
              "  'url': 'https://www.booking.com/hotel/ru/izmaylovo-beta.html'},\n",
              " {'address': 'Ulitsa Bakhrushina 11',\n",
              "  'currencycode': 'RUB',\n",
              "  'hotel_id': 803100,\n",
              "  'hotel_name': 'Ibis Moscow Centre Bakhrushina',\n",
              "  'main_photo_url': 'https://cf.bstatic.com/xdata/images/hotel/square60/250502012.jpg?k=3d618d018c48933ca21ac3aad389c4582d3248542df7cb183c42a042f809dc4c&o=',\n",
              "  'min_total_price': 12070,\n",
              "  'review_score': 8.8,\n",
              "  'url': 'https://www.booking.com/hotel/ru/ibis-moscow-centre-bakhrushina.html'},\n",
              " {'address': 'Shchipok Street 22 bld 1',\n",
              "  'currencycode': 'RUB',\n",
              "  'hotel_id': 179282,\n",
              "  'hotel_name': 'Ibis Moscow Paveletskaya',\n",
              "  'main_photo_url': 'https://cf.bstatic.com/xdata/images/hotel/square60/252017662.jpg?k=ffbd67b4611aa6fe651eb5a4150273dfd8d4551a96955995572fecc6da81ce71&o=',\n",
              "  'min_total_price': 18495,\n",
              "  'review_score': 8.0,\n",
              "  'url': 'https://www.booking.com/hotel/ru/ibis-moscow-paveletskaya.html'},\n",
              " {'address': 'Suvorovskaya Square 2/3',\n",
              "  'currencycode': 'RUB',\n",
              "  'hotel_id': 258097,\n",
              "  'hotel_name': 'Slavyanka',\n",
              "  'main_photo_url': 'https://cf.bstatic.com/xdata/images/hotel/square60/224838349.jpg?k=47799519a67ce09f5f6632ef46020a6f4392aee0bd2ab7bcc4042f14e42ed5c4&o=',\n",
              "  'min_total_price': 8500,\n",
              "  'review_score': 8.1,\n",
              "  'url': 'https://www.booking.com/hotel/ru/slavyanka.html'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xm9k6zGPiPE"
      },
      "source": [
        "# Intention classifier\n",
        "Here let's build a simple classifier of an input phrase.\n",
        "But first let us create BOT_CONFIG - it is a dictionary with intents, which have their phrase examples and some prepared answers. \n",
        "We will classify an input phrase by intent, and if there will be returned some intent, the algorithm will use a prepared response. If not - a failure phrase will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJcmZwDICaHe"
      },
      "source": [
        "BOT_CONFIG = {\n",
        "    'intents':{\n",
        "        'hello':{'examples': ['hej', 'dav', 'hi', 'hello', 'goddag','hej bot', 'dav bot', 'hi bot', 'hello bot', 'goddag bot', 'hej du'], 'responses': ['Hej! Hvordan kan jeg hjælpe dig?', 'Goddag! Hvordan kan jeg hjælpe dig?', 'Hey! Welcome! Hvordan kan jeg hjælpe dig?']},\n",
        "        'bye':{'examples': ['hej-hej', 'bye', 'ha en god dag', 'bye bot', 'tak hav en god dag', ' hav en god dag', 'ha det godt', 'bye-bye'], 'responses': ['Jeg håber du vil have en vidunderlig dag!','Jeg hjælper gerne. Hav en god dag!','Hej-hej!', 'Hav en rigtig god dag!', 'Farvel og tak!', 'Farvel!']},\n",
        "        'name':{'examples': ['hvordan hedder du', 'hvad hedder du', 'hvad er dit navn', 'dit navn', 'fortæl mig dit navn', 'fortæl dit navn'], \n",
        "                'responses': ['Jeg hedder AirbnbBot, jeg kan hjælpe dig med at reservere et hotelværelse. Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotelværelse', 'Jeg er AirbnbBot, jeg kan reservere et hotelværelse til dig. Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotelværelse']},\n",
        "        'sorry': {'examples': ['undskyld', 'det må du undskyld', 'med fejl', 'min fejl', 'det er med fejl', 'det er min fejl', 'undskyld bot', 'oh undskyld', 'undskyld for det'], 'responses': ['Det er helt i orden', 'Det er i orden', 'Du behøver ikke at undskylde dig']},\n",
        "        'help': {'examples': ['jeg vil book et billigt hotel med parkering', 'vi leder efter et hotel med parkering', 'vil have et hotel med parkering', 'vil book et hotel med parkering','jeg vil book et hotel med parkering', 'jeg leder efter et billigt hotel', 'jeg leder efter et hotel med parkering', 'jeg har brug for et hotel', 'jeg leder efter et hotel i københavn','jeg leder efter et hotel i buenos aires',\n",
        "                              'jeg leder efter et hotel i new york','jeg leder efter et hotel i moskva','jeg vil book et hotel i amsterdam', 'jeg vil book et hotel i buenos aires', 'jeg vil book et hotel i bangkok','jeg vil book et hotel i luxenburg', 'jeg vil book et hotel i københavn','jeg vil book et hotel','kan du book et hotel til mig', 'kan du booke hotel', 'jeg har også brug for at finde et sted at bo',\n",
        "                              'jeg leder efter et gæstehus i centrum af byen', 'jeg har brug for et sted at bo syd for byen', 'jeg leder efter oplysninger om et hotel i','kan du venligst hjælpe mig med at finde et sted at bo','jeg leder efter et hotel at bo på i centrum, kan du slå dette op for mig','jeg leder efter et bestemt hotel','jeg leder efter et sted at bo, der har en stjerne på ','jeg leder efter informationom hoteler i',\n",
        "                              'jeg leder efter et hotel i ','venligst book et hotel','jeg har brug for et sted at bo','kan du hjælpe dig med noget','jeg kunne ikke booke et hotel','jeg vil booke et hotel','jeg er på udkig efter et sted at bo','jeg vil reservere et hotel', 'reserver et hotelværelse i', 'kan du reservere et hotel', 'kan du reservere et hotelværelse', 'kan du reservere et hotelværelse for mig', 'kan du hjælpe mig', 'kan du hjælpe mig med at reservere',\n",
        "                              'jeg har brug for hjælp', 'jeg har brug for din hjælp', 'hjælp mig med det'], \n",
        "                 'responses': ['Jeg vil gerne hjælpe dig. Jeg kan reservere et hotelværelse til dig. Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotelværelse', 'Jeg vil gerne reservere et hotelværelse til dig. Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotelværelse']},\n",
        "        'answer': {'examples': ['jeg planlægger en tur til','jeg skal rejse til', 'jeg skal til', 'jeg skal til d og tilbage d', 'jeg skal til d', 'vi skal til', 'vi vil rejse til', 'vi skal rejse til'], \n",
        "                   'responses': ['Det er fint, tak! Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotelværelse til dig.']},\n",
        "        'bad words':{'examples': ['bland dig udenom', 'hold kæft', 'hold kæft bot','din kælling', 'dit røvhul', 'for fanden', 'for fanden bot', 'for helvede'], 'responses': ['Du skal ikke sværge her. Jeg er en anstændig bot.', 'Vær så venlig ikke at sværge. Jeg er en anstændig bot.']},\n",
        "        'how are you':{'examples': ['er det i orden', 'hvordan går det', 'hvordan går det med dig', 'hvordan har du det', 'hvordan fyler du dig'], \n",
        "                       'responses': ['Det går meget dodt, tak! Jeg er klar til at hjælpe dig med at reservere et hotelværelse. Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotelværelse', 'Jeg har det godt, tak! Jeg er klar til at hjælpe dig med at reservere et hotel værelse. Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotelværelse', \n",
        "                                     'Godt, mange tak! Jeg vil gerne hjælpe dig med at reservere et hotel værelse. Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotelværelse']},\n",
        "        'thanks':{'examples': ['tak for hjælpen', 'okey mange tak','okej tak','okay tak','det er det tak','tak det er alt', 'tak for din hjælp', 'tak', 'mange tak', 'det ville være alt tak'], 'responses': ['Jeg er glad for, at jeg var i stand til at hjælpe','Du er velkommen. Tak!', 'Tak! Glad for at kunne hjælpe', 'Du er meget velkommen!']},\n",
        "        \n",
        "    },\n",
        "    'failure_phrase': ['Undskyld, jeg kan ikke forstår det. Kan du skrive det igen? Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotel til dig.', 'Undskyld, jeg studerer bare at arbejde som bot og jeg kan ikke forstår nogle ting. Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotel til dig.']\n",
        "    \n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugSCWk0Gum9d"
      },
      "source": [
        "Then we construct a long vector of input data (`X_text`) and corresponding output (`y`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJG3i4NBg99f"
      },
      "source": [
        "X_text = []\n",
        "y = []\n",
        "for intent, intent_data in BOT_CONFIG['intents'].items():\n",
        "  for example in intent_data['examples']:\n",
        "    X_text.append(example)\n",
        "    y.append(intent)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x-pvuOLi859"
      },
      "source": [
        "Vectorization from a text to a number vector. For each word, the algorithm constructs a column in a matrix (by default `analyzer='word'`).\n",
        "But the experiments shows that n-gram method works better. Let's take 3-gram method. For example, `'Hello, world'` gives a list of subwords (3-grams) \n",
        "\n",
        "`['Hel', 'ell', 'llo', 'wor', 'orl', 'rld']` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztFceNSkihmx"
      },
      "source": [
        "# vectorizer = CountVectorizer()\n",
        "# vectorizer = TfidfVectorizer()\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3,3))\n",
        "# vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3,3))\n",
        "\n",
        "X = vectorizer.fit_transform(X_text)\n",
        "\n",
        "#let's shuffle before splitting into validational and\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idd7t2NxmUap"
      },
      "source": [
        "Let's use Linear classifier `LogisticRegression`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-v1PguhjNAb"
      },
      "source": [
        "#training of the model\n",
        "# clf = LogisticRegression(random_state = 0)\n",
        "clf = LinearSVC(random_state = 0)\n",
        "clf.fit(X,y)\n",
        "\n",
        "#predict function\n",
        "def classification(rep):\n",
        "  prediction = clf.predict(vectorizer.transform([rep]))\n",
        "  # print(prediction)\n",
        "  return prediction[0]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHprWzGAn4HO",
        "outputId": "c8dc4587-d6b0-4186-cab4-7ef06230ede6"
      },
      "source": [
        "# Estimation of quality\n",
        "from sklearn.metrics import precision_score\n",
        "y_pred = clf.predict(X_test)\n",
        "precision_score(y_test, y_pred, average='micro')\n",
        "# clf.score(X_test, y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnAKD0GZjasn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42155264-7c8a-443f-8829-043d71d254b4"
      },
      "source": [
        "#Let's check\n",
        "classification('hej kan du hjæelpe mig'), classification('bvvvvvvvv')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('help', 'hello')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHVN-TM8araO"
      },
      "source": [
        "Let us preprocess a input phrase - it is needed to transform it to lower case and remove sybmols"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZR2VPOrChJM"
      },
      "source": [
        "def clear(rep):\n",
        "    rep = rep.lower()\n",
        "    alphabet = '0123456789abcdefghijklmnopqrstuvwxyzåøæ- '\n",
        "    result = ''.join(symbol for symbol in rep if symbol in alphabet)\n",
        "    return result"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ3NWId6ClBL"
      },
      "source": [
        "def get_failure_phrase():\n",
        "    return random.choice(BOT_CONFIG['failure_phrase'])\n",
        "\n",
        "def too_many_enity_failure_phrase():\n",
        "    answer = 'Du har skrevet mere oplystninger end det var nødvendigt. Vær så venlig at give mig disse oplystninger: en by, en ankomsttid, en afgangstid.'\n",
        "    return answer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oswCRcN_iA-2"
      },
      "source": [
        "And it is also necessary to add calculation of the Levenshtein edit-distance between two strings. It will help to take attention to small mistakes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYoVcFR4CtM0"
      },
      "source": [
        "def classify_intent(rep):\n",
        "    rep = clear(rep)\n",
        "    intent = classification(rep) # classification algorithm always gives us an intention\n",
        "\n",
        "    # here we check the distance between answers of the intent and a user's replica\n",
        "    for intent, intent_data in BOT_CONFIG['intents'].items():\n",
        "        for example in intent_data['examples']:\n",
        "            example = clear(example)\n",
        "            distance = nltk.edit_distance(rep, example)\n",
        "            if example and distance/ len(example) < 0.45:\n",
        "              return intent\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7CD2n7JbHfB"
      },
      "source": [
        "And if intent is returned by the function, the chatbot uses some prepared answers (by intent)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhCh5voDCwfJ"
      },
      "source": [
        "def get_answer_by_intent(intent):\n",
        "    if intent in BOT_CONFIG['intents']:\n",
        "        responses = BOT_CONFIG['intents'][intent]['responses']\n",
        "        if responses:\n",
        "          return random.choice(responses)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKty9mrIvM3k"
      },
      "source": [
        "## Development of NER functionality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YgCWbUT8D70"
      },
      "source": [
        "Let's load a model which is based on a Spacy model and trained on **MultiWoZ** dataset, especially on the hotel related dialogues.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKt0f8iu8DEY"
      },
      "source": [
        "\n",
        "\n",
        "#load the model\n",
        "nlp = spacy.load(NER_MODEL_DIR)\n",
        "# nlp = spacy.load('en_core_web_lg')\n",
        "# nlp = spacy.load('da_core_news_lg')\n",
        "\n",
        "ner = nlp.get_pipe('ner')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G_isPcUbaGq"
      },
      "source": [
        "Let us create functions, which will help to identify date and location.\n",
        "It can be difficult to identify location only on danish dataset, so I made a translation of danish text into English and used built-in function GeoText."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtYLXrXfwQfR"
      },
      "source": [
        "# Utility functions to get and print output entities\n",
        "def get_ents(nlp, text):\n",
        "  docx = nlp(text)\n",
        "  out = []\n",
        "  for token in docx.ents:\n",
        "      out.append((token.text, token.start_char, token.end_char,token.label_))\n",
        "  return out\n",
        "\n",
        "def print_ents(nlp, text):\n",
        "  docx = nlp(text)\n",
        "  for token in docx.ents:\n",
        "      print(\"text:{}, start:{}, end:{}, label:{}\".format(token.text,token.start_char, token.end_char,token.label_))\n",
        "\n",
        "# Translate text\n",
        "def translate(text, target='en'):\n",
        "  if type(text) == list:\n",
        "    out = []\n",
        "    for t in text:\n",
        "      # print(t)\n",
        "      out.append(GoogleTranslator(source='auto', target=target).translate(t))\n",
        "    return out\n",
        "  return GoogleTranslator(source='auto', target=target).translate(text)\n",
        "\n",
        "# Date extracting function\n",
        "def extract_date(user_message, ents):\n",
        "  dates = []\n",
        "  for ent in ents:\n",
        "    if ent[3] == 'DATE':\n",
        "      parsed = dateparser.parse(ent[0])\n",
        "      if parsed:\n",
        "        dates.append(parsed)\n",
        "  # try to translate the message to english and use parser\n",
        "  translated_user_message = translate(user_message, target='en')\n",
        "\n",
        "  chars = \"\\|/`*_{}[]()>#+-.,:;!$\"\n",
        "  for c in chars:\n",
        "        translated_user_message = translated_user_message.replace(c, ' to ')\n",
        "  # print(translated_user_message)\n",
        "           # a generator will be returned by the datefinder module. \n",
        "          # I'm typecasting it to a list. \n",
        "  matches = list(datefinder.find_dates(translated_user_message))\n",
        "  dates += matches\n",
        "  # print(str(dates[0].date()))\n",
        "  return sorted(dates)\n",
        "\n",
        "\n",
        "\n",
        "#translate text to english and extract cities then return to source language\n",
        "def extract_loc (src_text, ents=None):\n",
        "  eng_text = translate(src_text, target='en')\n",
        "  eng_places = GeoText(eng_text)\n",
        "  # print(eng_places)\n",
        "  places = translate(eng_places.cities, target='da')\n",
        "  \n",
        "  if ents:\n",
        "    for ent in ents:\n",
        "      if ent[3] == 'GPE' or ent[3] == 'LOC':\n",
        "        places.append(ent[0])\n",
        "  \n",
        "  # print(places.cities)\n",
        "  return  list(set(places))\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myR0X2JJybgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60b68c5-f9ec-49b7-b483-905febfa90c1"
      },
      "source": [
        "# test\n",
        "print('entities: ', get_ents(nlp, \"Jeg elsker Paris, men jeg kan ikke lide Frankfurt. 5. januar skal jeg besøge. december 8skal jeg besøge\"))\n",
        "s = 'Jeg elsker Paris, men jeg kan ikke lide Frankfurt. 5. januar skal jeg besøge.'\n",
        "ents = get_ents(nlp, s)\n",
        "print(extract_date(s, ents ), ents)\n",
        "print(extract_loc(s, ents ), ents)\n",
        "\n",
        "# print_ents(nlp, \"Har du mulighed at finde et København?\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-30 18:06:07,028 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443\n",
            "2021-05-30 18:06:07,077 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 \"GET /m?hl=en&sl=auto&q=Jeg+elsker+Paris%2C+men+jeg+kan+ikke+lide+Frankfurt.+5.+januar+skal+jeg+bes%C3%B8ge. HTTP/1.1\" 200 None\n",
            "2021-05-30 18:06:07,151 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443\n",
            "2021-05-30 18:06:07,202 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 \"GET /m?hl=en&sl=auto&q=Jeg+elsker+Paris%2C+men+jeg+kan+ikke+lide+Frankfurt.+5.+januar+skal+jeg+bes%C3%B8ge. HTTP/1.1\" 200 None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "entities:  []\n",
            "[datetime.datetime(2021, 1, 5, 0, 0)] []\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-30 18:06:07,289 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443\n",
            "2021-05-30 18:06:07,320 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 \"GET /m?hl=da&sl=auto&q=Paris HTTP/1.1\" 200 None\n",
            "2021-05-30 18:06:07,398 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443\n",
            "2021-05-30 18:06:07,427 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 \"GET /m?sl=auto&q=Paris&tl=da HTTP/1.1\" 200 None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['Paris'] []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA6gVIdRA3ZC"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urfx6RXMQzZ-"
      },
      "source": [
        "## Development of a generative model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQauDPaVL4Qv"
      },
      "source": [
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
        "                               drop_prob=0.5, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "        self.vocab_size = len(tokens)\n",
        "        self.input_dim = n_hidden\n",
        "        self.output_size = len(tokens)\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.vocab_size)\n",
        "\n",
        "        # creating character dictionaries\n",
        "        self.chars = tokens\n",
        "        self.int2char = dict(enumerate(self.chars))\n",
        "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
        "        \n",
        "        # Define the LSTM layer\n",
        "        self.lstm = lstm_layer = nn.LSTM(self.input_dim, n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
        "        # Define a dropout layer\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.rnn = getattr(nn, 'LSTM')(len(self.chars), n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
        "\n",
        "        # Define the final, fully-connected output layer        \n",
        "        self.fc = nn.Linear(self.n_hidden, self.output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.decoder = nn.Linear(n_hidden, len(self.chars))\n",
        "\n",
        "        self.init_weights()\n",
        "        self.cuda()\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        ''' Forward pass through the network '''\n",
        "        x, h = self.rnn(x, hidden)\n",
        "        x = self.dropout(x)\n",
        "        # x = x.view(x.size(0)*x.size(1), self.n_hidden)\n",
        "        x = x.reshape(x.size(0)*x.size(1), self.n_hidden)\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x, h\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden\n",
        "\n",
        "    def init_weights(self):\n",
        "        ''' Initialize weights of decoder (fully connected layer) '''\n",
        "\n",
        "        # Apply bias tensor to all zeros\n",
        "        self.decoder.bias.data.fill_(0)\n",
        "\n",
        "        # Apply random uniform weights to decoder\n",
        "        self.decoder.weight.data.uniform_(-1, 1)\n",
        "\n",
        "        "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4h-nb-vfRMp"
      },
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "    # Initialize the the encoded array\n",
        "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
        "    \n",
        "    # Fill the appropriate elements with ones\n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "    \n",
        "    # Finally reshape it to get back to the original array\n",
        "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "    \n",
        "    return one_hot"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsilY3jNa92n"
      },
      "source": [
        "import json\n",
        "def load_json(directory, file):\n",
        "  with open(f'{directory}/{file}') as f:\n",
        "    db = json.load(f)\n",
        "  return db\n",
        "\n",
        "def upload_json(directory, file, db):\n",
        "  with open(f'{directory}/{file}', mode='w') as f:\n",
        "    json.dump(db,f)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIu8ubDibdNx"
      },
      "source": [
        "chars = load_json('/content/drive/MyDrive/ColabNotebooks/MultiWoz', 'chars.txt')\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqk9m34GMWQo",
        "outputId": "6148a982-890f-4b6e-b68a-58406ab16e7d"
      },
      "source": [
        "# Set model hyperparameters\n",
        "\n",
        "n_hidden = 256\n",
        "n_layers = 5\n",
        "\n",
        "# check if GPU is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU')\n",
        "else: \n",
        "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
        "\n",
        "net = CharRNN(chars, n_hidden, n_layers)\n",
        "print(net)\n",
        "net.load_state_dict(torch.load(GENERATIVE_MODEL_SH))\n",
        "net.eval()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU\n",
            "CharRNN(\n",
            "  (embedding): Embedding(97, 97)\n",
            "  (lstm): LSTM(256, 256, num_layers=5, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (rnn): LSTM(97, 256, num_layers=5, batch_first=True, dropout=0.5)\n",
            "  (fc): Linear(in_features=256, out_features=97, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (decoder): Linear(in_features=256, out_features=97, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (embedding): Embedding(97, 97)\n",
              "  (lstm): LSTM(256, 256, num_layers=5, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (rnn): LSTM(97, 256, num_layers=5, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=256, out_features=97, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (decoder): Linear(in_features=256, out_features=97, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUBxYO57M1Gj"
      },
      "source": [
        "def predict(net, char, h=None, top_k=None):\n",
        "        ''' Given a character, predict the next character.\n",
        "            Returns the predicted character and the hidden state.\n",
        "        '''\n",
        "        \n",
        "        # tensor inputs\n",
        "        x = np.array([[net.char2int[char]]])\n",
        "        x = one_hot_encode(x, len(net.chars))\n",
        "        inputs = torch.from_numpy(x)\n",
        "        \n",
        "        if(train_on_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "        \n",
        "        # detach hidden state from history\n",
        "        h = tuple([each.data for each in h])\n",
        "        # get the output of the model\n",
        "        out, h = net(inputs, h)\n",
        "\n",
        "        # get the character probabilities\n",
        "        p = F.softmax(out, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # move to cpu\n",
        "        \n",
        "        # get top characters\n",
        "        if top_k is None:\n",
        "            top_ch = np.arange(len(net.chars))\n",
        "        else:\n",
        "            p, top_ch = p.topk(top_k)\n",
        "            top_ch = top_ch.numpy().squeeze()\n",
        "        \n",
        "        # select the likely next character with some element of randomness\n",
        "        p = p.numpy().squeeze()\n",
        "        char = np.random.choice(top_ch, p=p/p.sum())\n",
        "        \n",
        "        # return the encoded value of the predicted char and the hidden state\n",
        "        return net.int2char[char], h"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YOGnK64NGOv"
      },
      "source": [
        "def sample(net, size = 500, prime='The', top_k=None):\n",
        "        \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    else:\n",
        "        net.cpu()\n",
        "    \n",
        "    net.eval() # eval mode\n",
        "    \n",
        "    # First off, run through the prime characters\n",
        "    chars = [ch for ch in prime]\n",
        "    h = net.init_hidden(1)\n",
        "    for ch in prime:\n",
        "        char, h = predict(net, ch, h, top_k=top_k)\n",
        "\n",
        "    chars.append(char)\n",
        "    \n",
        "    # Now pass in the previous character and get a new one\n",
        "    for ii in range(size):\n",
        "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "    answer = ''.join(chars)\n",
        "    # print(answer)\n",
        "    a = re.search(r'\\b(Person 2)\\b', answer)\n",
        "    slice1 = a.start() + 9\n",
        "    answer = answer[slice1:]\n",
        "    # print(answer)\n",
        "    try:\n",
        "      b = re.search(r'\\b(Person 1)\\b', answer)\n",
        "      slice2 = b.start() \n",
        "\n",
        "      # print(answer, answer[slice1 : slice2])\n",
        "      return answer[: slice2]\n",
        "    except:\n",
        "      return answer\n",
        "\n",
        "def generate_answer(replica):\n",
        "  return sample(net, size = 500, prime = replica, top_k=3)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vEIDzlNNkDm",
        "outputId": "5567dcac-670b-49be-90b7-a4ce5143ab5d"
      },
      "source": [
        "print(sample(net, 300, prime= 'Jeg skal finde er restaurant til at spise', top_k=5))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Okay, jeg har tog TR7199 og ankommer kl. 15:21, og køkken, hvilken dag rejser du? \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kAqjkWPfKDa"
      },
      "source": [
        "# ChatBot response function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRQFMNVeKFao"
      },
      "source": [
        "\n",
        "context_dict ={} # {chat_id:{'text':[], 'dates':[], 'locs':[], 'last_session':datetime() }}\n",
        "\n",
        "def clear_context_dict(chat_id):\n",
        "  return {'text':[], 'dates':[], 'locs':[], 'ents':[], 'last_session': datetime.today(), 'failure_qty':0 }\n",
        "\n",
        "def bot_responses(input_text, update, chat_id):\n",
        "  # store all messages in context_dict\n",
        "  context_dict.setdefault(chat_id, clear_context_dict(chat_id))\n",
        "  context_dict[chat_id]['text'].append(update.message.text)\n",
        "  \n",
        "  # NER and add new entitie to entity_dict\n",
        "  ents = get_ents(nlp, input_text)\n",
        "\n",
        "  dates = extract_date(input_text, ents)\n",
        "  locations = extract_loc (input_text, ents)\n",
        "  \n",
        "  context_dict[chat_id]['ents'] += ents\n",
        "  context_dict[chat_id]['dates'] += dates\n",
        "  context_dict[chat_id]['locs'] += locations\n",
        "\n",
        "  #Check last session\n",
        "  if datetime.today() - context_dict[chat_id]['last_session'] > timedelta( hours=20):\n",
        "    context_dict[chat_id] = clear_context_dict(chat_id)\n",
        "\n",
        "  \n",
        "  # remove copies\n",
        "  context_dict[chat_id]['locs'] = list(set(context_dict[chat_id]['locs']))\n",
        "  context_dict[chat_id]['dates'] = list(set(context_dict[chat_id]['dates']))\n",
        "  print('context_dict:', context_dict)\n",
        "  entities_qty = len(context_dict[chat_id]['locs']) + len(context_dict[chat_id]['dates'])\n",
        "\n",
        "\n",
        "  if entities_qty > 3:\n",
        "    context_dict[chat_id] = clear_context_dict(chat_id)\n",
        "    # context_dict[chat_id]['failure_qty'] += 1\n",
        "    return too_many_enity_failure_phrase()\n",
        "\n",
        "# booking API\n",
        "  elif entities_qty == 3:\n",
        "    if len(context_dict[chat_id]['locs'])==1 and len(context_dict[chat_id]['dates'])==2:\n",
        "      city = context_dict[chat_id]['locs'][-1]\n",
        "      dates_travel = context_dict[chat_id]['dates']\n",
        "      context_dict[chat_id] = clear_context_dict(chat_id)\n",
        "      return booking_request(city, dates_travel)\n",
        "    else:\n",
        "      context_dict[chat_id] = clear_context_dict(chat_id)\n",
        "      context_dict[chat_id]['failure_qty'] += 1\n",
        "      return too_many_enity_failure_phrase()\n",
        "# generate answer\n",
        "  elif context_dict[chat_id]['failure_qty'] >= 3:\n",
        "  # Using generative model\n",
        "    # answer = generate_answer(user_message)\n",
        "    # if answer:\n",
        "    #     return answer + user_message + out_text\n",
        "    return generate_answer(input_text)\n",
        "  else:\n",
        "    # NLU\n",
        "    user_message = clear(input_text)\n",
        "    intent = classify_intent(user_message)\n",
        "    # print(intent)\n",
        "\n",
        "    # Answer generation - choose an answer\n",
        "    if intent:\n",
        "        answer = get_answer_by_intent(intent)\n",
        "        if answer:\n",
        "            return answer\n",
        "\n",
        "\n",
        "\n",
        "  # failure answer if bot doesn't catch a user\n",
        "    context_dict[chat_id]['failure_qty'] += 1\n",
        "    return get_failure_phrase()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mppb75lxl0h-"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mywnI_GxfZlp"
      },
      "source": [
        "## ChatBot commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP4SA20pVX9l"
      },
      "source": [
        "def start_command(update, context):\n",
        "  update.message.reply_text('Jeg er AirBnb Bot, jeg kan hjælpe dig med at finde et hotel i alle lande. Skriv noget til at begynde!')\n",
        "\n",
        "def help_command(update, context):\n",
        "  update.message.reply_text('Hvis du har brugt for hjælp, kan du ringe til +1222-345-6789')\n",
        "\n",
        "\n",
        "def handle_message(update, context):\n",
        "  chat_id = update.message.chat_id\n",
        "  print(update, context)\n",
        "  print(update.message, context)\n",
        "  text = str(update.message.text)\n",
        "  response = bot_responses(text, update, chat_id)\n",
        "  print(response)\n",
        "  if type(response) == list:\n",
        "    update.message.reply_text('Her kan du se flere hoteller, der måske passer dig! Hav en rigtig god dag!')\n",
        "    for elem in response:\n",
        "      text=elem['hotel_name'] + ' (Bedømmelse: ' + str(elem['review_score']) + ') minimumspris=' + str(elem['min_total_price']) + ' ' + elem['currencycode']\n",
        "      update.message.reply_text(text,\n",
        "                                reply_markup = telegram.InlineKeyboardMarkup([\n",
        "                                    [telegram.InlineKeyboardButton(text='link', url=elem['url'])],\n",
        "                                ]))\n",
        "      # update.message.send_photo(chat_id=chat_id,\n",
        "      #                           photo=elem['main_photo_url']\n",
        "      #                       )\n",
        "\n",
        "\n",
        "  else:\n",
        "    update.message.reply_text(response)\n",
        "\n",
        "def error(update, context):\n",
        "  print(f'Update {update} caused error {context.error}')\n",
        "\n",
        "def main():\n",
        "  updater = Updater(BOT_KEY, use_context = True)\n",
        "  dp = updater.dispatcher\n",
        "  dp.add_handler(CommandHandler('start', start_command))\n",
        "  dp.add_handler(CommandHandler('help', help_command))\n",
        "  dp.add_handler(MessageHandler(Filters.text, handle_message))\n",
        "  dp.add_error_handler(error)\n",
        "  updater.start_polling()\n",
        "  logger = logging.getLogger()\n",
        "  logger.setLevel(logging.INFO)\n",
        "  updater.idle()\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqOKEVeqfmHL"
      },
      "source": [
        "# Call the ChatBot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7e7a-152CN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a3f6ced-5c6d-412f-b629-a4d8ece20fa8"
      },
      "source": [
        "main()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-30 18:54:56,141 - apscheduler.scheduler - INFO - Scheduler started\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'update_id': 739756797, 'message': {'message_id': 733, 'date': 1622400921, 'chat': {'id': 756484216, 'type': 'private', 'username': 'lsharaborina', 'first_name': 'lsharaborina'}, 'text': 'Hvilke bog kan du lige?', 'entities': [], 'caption_entities': [], 'photo': [], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 756484216, 'first_name': 'lsharaborina', 'is_bot': False, 'username': 'lsharaborina', 'language_code': 'ru'}}} <telegram.ext.callbackcontext.CallbackContext object at 0x7f9e201f8b10>\n",
            "{'message_id': 733, 'date': 1622400921, 'chat': {'id': 756484216, 'type': 'private', 'username': 'lsharaborina', 'first_name': 'lsharaborina'}, 'text': 'Hvilke bog kan du lige?', 'entities': [], 'caption_entities': [], 'photo': [], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 756484216, 'first_name': 'lsharaborina', 'is_bot': False, 'username': 'lsharaborina', 'language_code': 'ru'}} <telegram.ext.callbackcontext.CallbackContext object at 0x7f9e201f8b10>\n",
            "context_dict: {442277882: {'text': ['Hund dial fjrieis', 'Fhdhdjdk', 'Xhfjddks', 'Jeg skal finde er restaurant til at spise', 'Jeg skal finde er restaurant til at spise'], 'dates': [], 'locs': [], 'ents': [], 'last_session': datetime.datetime(2021, 5, 30, 18, 40, 4, 605840), 'failure_qty': 4}, 756484216: {'text': ['Hvilke bog kan du lige?'], 'dates': [], 'locs': [], 'ents': [], 'last_session': datetime.datetime(2021, 5, 30, 18, 55, 21, 902447), 'failure_qty': 0}}\n",
            "Undskyld, jeg kan ikke forstår det. Kan du skrive det igen? Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotel til dig.\n",
            "{'update_id': 739756798, 'message': {'message_id': 735, 'date': 1622400930, 'chat': {'id': 756484216, 'type': 'private', 'username': 'lsharaborina', 'first_name': 'lsharaborina'}, 'text': 'Hvilke bog kan du lige?', 'entities': [], 'caption_entities': [], 'photo': [], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 756484216, 'first_name': 'lsharaborina', 'is_bot': False, 'username': 'lsharaborina', 'language_code': 'ru'}}} <telegram.ext.callbackcontext.CallbackContext object at 0x7f9e203696d0>\n",
            "{'message_id': 735, 'date': 1622400930, 'chat': {'id': 756484216, 'type': 'private', 'username': 'lsharaborina', 'first_name': 'lsharaborina'}, 'text': 'Hvilke bog kan du lige?', 'entities': [], 'caption_entities': [], 'photo': [], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 756484216, 'first_name': 'lsharaborina', 'is_bot': False, 'username': 'lsharaborina', 'language_code': 'ru'}} <telegram.ext.callbackcontext.CallbackContext object at 0x7f9e203696d0>\n",
            "context_dict: {442277882: {'text': ['Hund dial fjrieis', 'Fhdhdjdk', 'Xhfjddks', 'Jeg skal finde er restaurant til at spise', 'Jeg skal finde er restaurant til at spise'], 'dates': [], 'locs': [], 'ents': [], 'last_session': datetime.datetime(2021, 5, 30, 18, 40, 4, 605840), 'failure_qty': 4}, 756484216: {'text': ['Hvilke bog kan du lige?', 'Hvilke bog kan du lige?'], 'dates': [], 'locs': [], 'ents': [], 'last_session': datetime.datetime(2021, 5, 30, 18, 55, 21, 902447), 'failure_qty': 1}}\n",
            "Undskyld, jeg studerer bare at arbejde som bot og jeg kan ikke forstår nogle ting. Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotel til dig.\n",
            "{'update_id': 739756799, 'message': {'message_id': 737, 'date': 1622400933, 'chat': {'id': 756484216, 'type': 'private', 'username': 'lsharaborina', 'first_name': 'lsharaborina'}, 'text': 'Hvilke bog kan du lige?', 'entities': [], 'caption_entities': [], 'photo': [], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 756484216, 'first_name': 'lsharaborina', 'is_bot': False, 'username': 'lsharaborina', 'language_code': 'ru'}}} <telegram.ext.callbackcontext.CallbackContext object at 0x7f9e201e75d0>\n",
            "{'message_id': 737, 'date': 1622400933, 'chat': {'id': 756484216, 'type': 'private', 'username': 'lsharaborina', 'first_name': 'lsharaborina'}, 'text': 'Hvilke bog kan du lige?', 'entities': [], 'caption_entities': [], 'photo': [], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 756484216, 'first_name': 'lsharaborina', 'is_bot': False, 'username': 'lsharaborina', 'language_code': 'ru'}} <telegram.ext.callbackcontext.CallbackContext object at 0x7f9e201e75d0>\n",
            "context_dict: {442277882: {'text': ['Hund dial fjrieis', 'Fhdhdjdk', 'Xhfjddks', 'Jeg skal finde er restaurant til at spise', 'Jeg skal finde er restaurant til at spise'], 'dates': [], 'locs': [], 'ents': [], 'last_session': datetime.datetime(2021, 5, 30, 18, 40, 4, 605840), 'failure_qty': 4}, 756484216: {'text': ['Hvilke bog kan du lige?', 'Hvilke bog kan du lige?', 'Hvilke bog kan du lige?'], 'dates': [], 'locs': [], 'ents': [], 'last_session': datetime.datetime(2021, 5, 30, 18, 55, 21, 902447), 'failure_qty': 2}}\n",
            "Undskyld, jeg studerer bare at arbejde som bot og jeg kan ikke forstår nogle ting. Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotel til dig.\n",
            "{'update_id': 739756800, 'message': {'message_id': 739, 'date': 1622400937, 'chat': {'id': 756484216, 'type': 'private', 'username': 'lsharaborina', 'first_name': 'lsharaborina'}, 'text': 'Hvilke bog kan du lige?', 'entities': [], 'caption_entities': [], 'photo': [], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 756484216, 'first_name': 'lsharaborina', 'is_bot': False, 'username': 'lsharaborina', 'language_code': 'ru'}}} <telegram.ext.callbackcontext.CallbackContext object at 0x7f9e20345c50>\n",
            "{'message_id': 739, 'date': 1622400937, 'chat': {'id': 756484216, 'type': 'private', 'username': 'lsharaborina', 'first_name': 'lsharaborina'}, 'text': 'Hvilke bog kan du lige?', 'entities': [], 'caption_entities': [], 'photo': [], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 756484216, 'first_name': 'lsharaborina', 'is_bot': False, 'username': 'lsharaborina', 'language_code': 'ru'}} <telegram.ext.callbackcontext.CallbackContext object at 0x7f9e20345c50>\n",
            "context_dict: {442277882: {'text': ['Hund dial fjrieis', 'Fhdhdjdk', 'Xhfjddks', 'Jeg skal finde er restaurant til at spise', 'Jeg skal finde er restaurant til at spise'], 'dates': [], 'locs': [], 'ents': [], 'last_session': datetime.datetime(2021, 5, 30, 18, 40, 4, 605840), 'failure_qty': 4}, 756484216: {'text': ['Hvilke bog kan du lige?', 'Hvilke bog kan du lige?', 'Hvilke bog kan du lige?', 'Hvilke bog kan du lige?'], 'dates': [], 'locs': [], 'ents': [], 'last_session': datetime.datetime(2021, 5, 30, 18, 55, 21, 902447), 'failure_qty': 3}}\n",
            "Undskyld, jeg kan ikke forstår det. Kan du skrive det igen? Kan du venligst give mig følgende information: en by, en ankomsttid, en afgangstid. Og jeg vil finde et hotel til dig.\n",
            "{'update_id': 739756801, 'message': {'message_id': 741, 'date': 1622400941, 'chat': {'id': 756484216, 'type': 'private', 'username': 'lsharaborina', 'first_name': 'lsharaborina'}, 'text': 'Hvilke bog kan du lige?', 'entities': [], 'caption_entities': [], 'photo': [], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 756484216, 'first_name': 'lsharaborina', 'is_bot': False, 'username': 'lsharaborina', 'language_code': 'ru'}}} <telegram.ext.callbackcontext.CallbackContext object at 0x7f9e20257950>\n",
            "{'message_id': 741, 'date': 1622400941, 'chat': {'id': 756484216, 'type': 'private', 'username': 'lsharaborina', 'first_name': 'lsharaborina'}, 'text': 'Hvilke bog kan du lige?', 'entities': [], 'caption_entities': [], 'photo': [], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 756484216, 'first_name': 'lsharaborina', 'is_bot': False, 'username': 'lsharaborina', 'language_code': 'ru'}} <telegram.ext.callbackcontext.CallbackContext object at 0x7f9e20257950>\n",
            "context_dict: {442277882: {'text': ['Hund dial fjrieis', 'Fhdhdjdk', 'Xhfjddks', 'Jeg skal finde er restaurant til at spise', 'Jeg skal finde er restaurant til at spise'], 'dates': [], 'locs': [], 'ents': [], 'last_session': datetime.datetime(2021, 5, 30, 18, 40, 4, 605840), 'failure_qty': 4}, 756484216: {'text': ['Hvilke bog kan du lige?', 'Hvilke bog kan du lige?', 'Hvilke bog kan du lige?', 'Hvilke bog kan du lige?', 'Hvilke bog kan du lige?'], 'dates': [], 'locs': [], 'ents': [], 'last_session': datetime.datetime(2021, 5, 30, 18, 55, 21, 902447), 'failure_qty': 4}}\n",
            " Hvad med Chrastistnotos på Cambridge Arts Theatre i centrum af byen? \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-30 18:55:56,968 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n",
            "2021-05-30 18:55:56,973 - apscheduler.scheduler - INFO - Scheduler has been shut down\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUW9ZP-Tjo_f"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}